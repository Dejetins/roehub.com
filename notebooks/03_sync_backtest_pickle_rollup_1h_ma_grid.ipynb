{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title",
      "metadata": {},
      "source": [
        "# Sync Backtest (Pickle -> Rollup 1h -> MA Grid)\n",
        "\n",
        "Loads candle data from a pickle file, rolls up to `1h`, then runs sync-style staged backtests on a MA grid:\n",
        "\n",
        "- `ma.sma` windows `5..200` step `1`\n",
        "- `ma.ema` windows `5..200` step `1`\n",
        "\n",
        "Notes:\n",
        "- This notebook is offline (no DB).\n",
        "- Requires `numba` + project deps for the real indicator compute engine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "from dataclasses import asdict\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from trading.contexts.backtest.adapters.outbound.config.backtest_runtime_config import (\n",
        "    load_backtest_runtime_config,\n",
        ")\n",
        "from trading.contexts.backtest.application.dto import RunBacktestTemplate\n",
        "from trading.contexts.backtest.application.services.close_fill_scorer_v1 import (\n",
        "    CloseFillBacktestStagedScorerV1,\n",
        ")\n",
        "from trading.contexts.backtest.application.services.staged_runner_v1 import BacktestStagedRunnerV1\n",
        "from trading.contexts.indicators.application.dto import CandleArrays\n",
        "from trading.contexts.indicators.domain.entities import IndicatorId\n",
        "from trading.contexts.indicators.domain.specifications import ExplicitValuesSpec, GridSpec\n",
        "from trading.platform.config.indicators_compute_numba import IndicatorsComputeNumbaConfig\n",
        "from trading.shared_kernel.primitives import (\n",
        "    InstrumentId,\n",
        "    Timeframe,\n",
        "    TimeRange,\n",
        "    UtcTimestamp,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from trading.contexts.indicators.adapters.outbound.compute_numba.engine import (\n",
        "        NumbaIndicatorCompute,\n",
        "    )\n",
        "    from trading.contexts.indicators.domain.definitions import all_defs\n",
        "\n",
        "    HAVE_NUMBA = True\n",
        "except Exception as e:\n",
        "    HAVE_NUMBA = False\n",
        "    _NUMBA_IMPORT_ERROR = e\n",
        "\n",
        "PICKLE_PATH = Path(\"/ABS/PATH/TO/candles.pkl\")  # TODO: set this\n",
        "ROLLUP_TO = Timeframe(\"1h\")\n",
        "WINDOWS = tuple(range(5, 201))\n",
        "INDICATORS = (\"ma.sma\", \"ma.ema\")\n",
        "\n",
        "PRESELECT = 60\n",
        "TOP_K = 30\n",
        "TOP_TRADES_N = 3\n",
        "\n",
        "# Numba compute knob for notebook runs.\n",
        "NUMBA_NUM_THREADS = 1\n",
        "NUMBA_CACHE_DIR = \".cache/numba/notebooks\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_pickle",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _utc_dt_from_ms(ms: int) -> datetime:\n",
        "    return datetime.fromtimestamp(ms / 1000.0, tz=timezone.utc)\n",
        "\n",
        "\n",
        "def _to_float32(x: np.ndarray) -> np.ndarray:\n",
        "    return np.ascontiguousarray(x, dtype=np.float32)\n",
        "\n",
        "\n",
        "def _to_int64(x: np.ndarray) -> np.ndarray:\n",
        "    return np.ascontiguousarray(x, dtype=np.int64)\n",
        "\n",
        "\n",
        "def _to_ts_open_ms(values: object) -> np.ndarray:\n",
        "    \"\"\"Normalize time_open/ts_open payload into epoch milliseconds int64.\"\"\"\n",
        "    raw = np.asarray(values)\n",
        "    if np.issubdtype(raw.dtype, np.datetime64):\n",
        "        return np.ascontiguousarray(raw.astype(\"datetime64[ms]\").astype(np.int64))\n",
        "    if raw.dtype == object:\n",
        "        out = np.empty(int(raw.shape[0]), dtype=np.int64)\n",
        "        for i, v in enumerate(raw.tolist()):\n",
        "            if v is None:\n",
        "                raise ValueError(\"time_open contains None\")\n",
        "            # pandas.Timestamp (ns since epoch)\n",
        "            value_attr = getattr(v, \"value\", None)\n",
        "            if isinstance(value_attr, (int, np.integer)):\n",
        "                out[i] = int(int(value_attr) // 1_000_000)\n",
        "                continue\n",
        "            if isinstance(v, datetime):\n",
        "                dt = v if v.tzinfo is not None else v.replace(tzinfo=timezone.utc)\n",
        "                out[i] = int(dt.timestamp() * 1000.0)\n",
        "                continue\n",
        "            out[i] = int(v)\n",
        "        return np.ascontiguousarray(out, dtype=np.int64)\n",
        "    return np.ascontiguousarray(raw, dtype=np.int64)\n",
        "\n",
        "\n",
        "def load_candles_from_pickle(path: Path) -> CandleArrays:\n",
        "    \"\"\"\n",
        "    Load CandleArrays from a pickle file.\n",
        "\n",
        "    Supports these pickle payloads:\n",
        "    - CandleArrays\n",
        "    - dict with keys: ts_open (or time_open), open, high, low, close, volume\n",
        "      (optional: market_id, symbol, timeframe)\n",
        "    - pandas.DataFrame with columns: ts_open (or time_open) + open/high/low/close/volume\n",
        "    \"\"\"\n",
        "    try:\n",
        "        obj = pickle.loads(path.read_bytes())\n",
        "    except ModuleNotFoundError as e:\n",
        "        if getattr(e, 'name', None) == 'pandas':\n",
        "            raise RuntimeError(\n",
        "                'This pickle requires pandas to unpickle. '\n",
        "                'Either install pandas (e.g. `uv pip install pandas`) '\n",
        "                'or re-save the pickle as CandleArrays / dict-of-arrays.'\n",
        "            ) from e\n",
        "        raise\n",
        "    if isinstance(obj, CandleArrays):\n",
        "        return obj\n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "        time_key = None\n",
        "        if \"ts_open\" in obj:\n",
        "            time_key = \"ts_open\"\n",
        "        elif \"time_open\" in obj:\n",
        "            time_key = \"time_open\"\n",
        "\n",
        "        required = {\n",
        "            \"open\",\n",
        "            \"high\",\n",
        "            \"low\",\n",
        "            \"close\",\n",
        "            \"volume\",\n",
        "        }\n",
        "        if time_key is not None and required.issubset(obj.keys()):\n",
        "            from trading.shared_kernel.primitives import MarketId, Symbol\n",
        "\n",
        "            ts_open = _to_ts_open_ms(obj[time_key])\n",
        "            tf = Timeframe(str(obj.get(\"timeframe\", \"1m\")))\n",
        "            tf_ms = int(tf.duration().total_seconds() * 1000)\n",
        "            start = _utc_dt_from_ms(int(ts_open[0]))\n",
        "            end = _utc_dt_from_ms(int(ts_open[-1]) + tf_ms)\n",
        "\n",
        "            return CandleArrays(\n",
        "                market_id=MarketId(int(obj.get(\"market_id\", 1))),\n",
        "                symbol=Symbol(str(obj.get(\"symbol\", \"BTCUSDT\"))),\n",
        "                time_range=TimeRange(UtcTimestamp(start), UtcTimestamp(end)),\n",
        "                timeframe=tf,\n",
        "                ts_open=ts_open,\n",
        "                open=_to_float32(np.asarray(obj[\"open\"])),\n",
        "                high=_to_float32(np.asarray(obj[\"high\"])),\n",
        "                low=_to_float32(np.asarray(obj[\"low\"])),\n",
        "                close=_to_float32(np.asarray(obj[\"close\"])),\n",
        "                volume=_to_float32(np.asarray(obj[\"volume\"])),\n",
        "            )\n",
        "\n",
        "    # Optional: pandas.DataFrame support (requires pandas to unpickle).\n",
        "    if hasattr(obj, \"__class__\") and obj.__class__.__name__ == \"DataFrame\":\n",
        "        df = obj\n",
        "        time_col = None\n",
        "        if \"ts_open\" in df.columns:\n",
        "            time_col = \"ts_open\"\n",
        "        elif \"time_open\" in df.columns:\n",
        "            time_col = \"time_open\"\n",
        "        if time_col is None:\n",
        "            raise KeyError(\"missing DataFrame column: ts_open/time_open\")\n",
        "\n",
        "        for col in (\"open\", \"high\", \"low\", \"close\", \"volume\"):\n",
        "            if col not in df.columns:\n",
        "                raise KeyError(f\"missing DataFrame column: {col}\")\n",
        "\n",
        "        from trading.shared_kernel.primitives import MarketId, Symbol\n",
        "\n",
        "        ts_open = _to_ts_open_ms(df[time_col].to_numpy())\n",
        "        tf = Timeframe(str(getattr(df, \"timeframe\", \"1m\")))\n",
        "        tf_ms = int(tf.duration().total_seconds() * 1000)\n",
        "        start = _utc_dt_from_ms(int(ts_open[0]))\n",
        "        end = _utc_dt_from_ms(int(ts_open[-1]) + tf_ms)\n",
        "        market_id = int(getattr(df, \"market_id\", 1))\n",
        "        symbol = str(getattr(df, \"symbol\", \"BTCUSDT\"))\n",
        "\n",
        "        return CandleArrays(\n",
        "            market_id=MarketId(market_id),\n",
        "            symbol=Symbol(symbol),\n",
        "            time_range=TimeRange(UtcTimestamp(start), UtcTimestamp(end)),\n",
        "            timeframe=tf,\n",
        "            ts_open=ts_open,\n",
        "            open=_to_float32(df[\"open\"].to_numpy()),\n",
        "            high=_to_float32(df[\"high\"].to_numpy()),\n",
        "            low=_to_float32(df[\"low\"].to_numpy()),\n",
        "            close=_to_float32(df[\"close\"].to_numpy()),\n",
        "            volume=_to_float32(df[\"volume\"].to_numpy()),\n",
        "        )\n",
        "\n",
        "    raise TypeError(f\"unsupported pickle payload type: {type(obj)!r}\")\n",
        "\n",
        "\n",
        "candles_raw = load_candles_from_pickle(PICKLE_PATH)\n",
        "candles_raw.timeframe, candles_raw.close.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rollup",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rollup_candles_to_1h(candles: CandleArrays) -> CandleArrays:\n",
        "    \"\"\"Roll up candles to 1h using deterministic OHLCV reduceat operations.\"\"\"\n",
        "    if candles.ts_open.shape[0] == 0:\n",
        "        raise ValueError(\"candles are empty\")\n",
        "\n",
        "    tf_out = Timeframe(\"1h\")\n",
        "    hour_ms = int(tf_out.duration().total_seconds() * 1000)\n",
        "\n",
        "    ts = _to_int64(candles.ts_open)\n",
        "    buckets = (ts // hour_ms).astype(np.int64)\n",
        "    change = np.nonzero(buckets[1:] != buckets[:-1])[0] + 1\n",
        "    starts = np.concatenate((np.asarray((0,), dtype=np.int64), change.astype(np.int64)))\n",
        "    ends = np.concatenate((starts[1:], np.asarray((ts.shape[0],), dtype=np.int64)))\n",
        "\n",
        "    open_ = _to_float32(candles.open)\n",
        "    high = _to_float32(candles.high)\n",
        "    low = _to_float32(candles.low)\n",
        "    close = _to_float32(candles.close)\n",
        "    volume = _to_float32(candles.volume)\n",
        "\n",
        "    ts_open_1h = (buckets[starts] * hour_ms).astype(np.int64)\n",
        "    open_1h = open_[starts]\n",
        "    high_1h = np.maximum.reduceat(high, starts)\n",
        "    low_1h = np.minimum.reduceat(low, starts)\n",
        "    volume_1h = np.add.reduceat(volume, starts)\n",
        "    close_1h = close[(ends - 1).astype(np.int64)]\n",
        "\n",
        "    start = _utc_dt_from_ms(int(ts_open_1h[0]))\n",
        "    end = _utc_dt_from_ms(int(ts_open_1h[-1]) + hour_ms)\n",
        "\n",
        "    return CandleArrays(\n",
        "        market_id=candles.market_id,\n",
        "        symbol=candles.symbol,\n",
        "        time_range=TimeRange(UtcTimestamp(start), UtcTimestamp(end)),\n",
        "        timeframe=tf_out,\n",
        "        ts_open=_to_int64(ts_open_1h),\n",
        "        open=_to_float32(open_1h),\n",
        "        high=_to_float32(high_1h),\n",
        "        low=_to_float32(low_1h),\n",
        "        close=_to_float32(close_1h),\n",
        "        volume=_to_float32(volume_1h),\n",
        "    )\n",
        "\n",
        "\n",
        "candles_1h = rollup_candles_to_1h(candles_raw)\n",
        "candles_1h.timeframe, candles_raw.close.shape, candles_1h.close.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compute_engine",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not HAVE_NUMBA:\n",
        "    raise RuntimeError(f\"Numba compute engine is not available: {_NUMBA_IMPORT_ERROR!r}\")\n",
        "\n",
        "rt = load_backtest_runtime_config(\"configs/dev/backtest.yaml\")\n",
        "\n",
        "numba_cfg = IndicatorsComputeNumbaConfig(\n",
        "    numba_num_threads=NUMBA_NUM_THREADS,\n",
        "    numba_cache_dir=NUMBA_CACHE_DIR,\n",
        "    max_compute_bytes_total=rt.guards.max_compute_bytes_total,\n",
        "    max_variants_per_compute=rt.guards.max_variants_per_compute,\n",
        ")\n",
        "indicator_compute = NumbaIndicatorCompute(defs=all_defs(), config=numba_cfg)\n",
        "\n",
        "# Optional warmup (JIT).\n",
        "indicator_compute.warmup()\n",
        "\n",
        "asdict(rt) if hasattr(rt, \"__dict__\") else rt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run_backtests",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_ma_grid(*, candles: CandleArrays, indicator_id: str) -> dict[str, object]:\n",
        "    bars = int(candles.close.shape[0])\n",
        "    warmup = int(rt.warmup_bars_default)\n",
        "    if bars <= warmup + 10:\n",
        "        raise ValueError(f\"not enough bars after rollup: bars={bars}, warmup={warmup}\")\n",
        "\n",
        "    grid = GridSpec(\n",
        "        indicator_id=IndicatorId(indicator_id),\n",
        "        source=ExplicitValuesSpec(name=\"source\", values=(\"close\",)),\n",
        "        params={\n",
        "            \"window\": ExplicitValuesSpec(name=\"window\", values=WINDOWS),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    template = RunBacktestTemplate(\n",
        "        instrument_id=InstrumentId(candles.market_id, candles.symbol),\n",
        "        timeframe=candles.timeframe,\n",
        "        indicator_grids=(grid,),\n",
        "        indicator_selections=(),\n",
        "        signal_grids=None,\n",
        "        risk_grid=None,\n",
        "        direction_mode=\"long-short\",\n",
        "        sizing_mode=\"all_in\",\n",
        "        risk_params=None,\n",
        "        execution_params=None,\n",
        "    )\n",
        "\n",
        "    scorer = CloseFillBacktestStagedScorerV1(\n",
        "        indicator_compute=indicator_compute,\n",
        "        direction_mode=template.direction_mode,\n",
        "        sizing_mode=template.sizing_mode,\n",
        "        execution_params=template.execution_params or {},\n",
        "        market_id=candles.market_id.value,\n",
        "        target_slice=slice(warmup, bars),\n",
        "        init_cash_quote_default=rt.execution.init_cash_quote_default,\n",
        "        fixed_quote_default=rt.execution.fixed_quote_default,\n",
        "        safe_profit_percent_default=rt.execution.safe_profit_percent_default,\n",
        "        slippage_pct_default=rt.execution.slippage_pct_default,\n",
        "        fee_pct_default_by_market_id=rt.execution.fee_pct_default_by_market_id,\n",
        "        max_variants_guard=rt.guards.max_variants_per_compute,\n",
        "        max_compute_bytes_total=rt.guards.max_compute_bytes_total,\n",
        "    )\n",
        "\n",
        "    runner = BacktestStagedRunnerV1(parallel_workers=1)\n",
        "    t0 = time.perf_counter()\n",
        "    res = runner.run(\n",
        "        template=template,\n",
        "        candles=candles,\n",
        "        preselect=PRESELECT,\n",
        "        top_k=TOP_K,\n",
        "        indicator_compute=indicator_compute,\n",
        "        scorer=scorer,\n",
        "        defaults_provider=None,\n",
        "        max_variants_per_compute=rt.guards.max_variants_per_compute,\n",
        "        max_compute_bytes_total=rt.guards.max_compute_bytes_total,\n",
        "        requested_time_range=candles.time_range,\n",
        "        top_trades_n=TOP_TRADES_N,\n",
        "    )\n",
        "    dt = time.perf_counter() - t0\n",
        "\n",
        "    top = [\n",
        "        {\n",
        "            \"rank\": i,\n",
        "            \"variant_key\": v.variant_key,\n",
        "            \"indicator_variant_key\": v.indicator_variant_key,\n",
        "            \"total_return_pct\": float(v.total_return_pct),\n",
        "        }\n",
        "        for i, v in enumerate(res.variants, start=1)\n",
        "    ]\n",
        "    return {\n",
        "        \"indicator_id\": indicator_id,\n",
        "        \"bars\": bars,\n",
        "        \"warmup\": warmup,\n",
        "        \"stage_a_variants_total\": int(res.stage_a_variants_total),\n",
        "        \"stage_b_variants_total\": int(res.stage_b_variants_total),\n",
        "        \"elapsed_s\": float(dt),\n",
        "        \"top\": top,\n",
        "    }\n",
        "\n",
        "\n",
        "results = [\n",
        "    run_ma_grid(candles=candles_1h, indicator_id=indicator_id)\n",
        "    for indicator_id in INDICATORS\n",
        "]\n",
        "results\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
